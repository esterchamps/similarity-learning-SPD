{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ester\\faculdade\\tcc\\code\\.conda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from itertools import product\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from image_utils import load_grayscale_image\n",
    "import numpy as np\n",
    "from skimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('training_results_2\\\\evaluated_model_27022024_182439.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 150, 220, 1) dtype=float32 (created by layer 'input_1')>,\n",
       " <KerasTensor: shape=(None, 531) dtype=float32 (created by layer 'input_2')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_3')>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachnorm = model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 75, 110, 12) dtype=float32 (created by layer 'conv2d')>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_layer = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 75, 110, 12)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_conv_layer.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = tf.keras.Model(inputs=model.input, outputs=model.layers[1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x1e52f033f10>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_layer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_image = load_grayscale_image('preprocessed_images_protocol_2\\\\data_protocol_2_preprocessing\\\\protocol_2_preprocessed_images\\\\2\\\\cf-2-2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 220)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(some_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image = some_image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.expand_dims(normalized_image, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = np.ones((531,))\n",
    "input2 = np.ones((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_max = np.expand_dims(np.ones_like(normalized_image), axis=-1)\n",
    "input_min = np.expand_dims(np.zeros_like(normalized_image), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_intermediate_output = intermediate_layer_model([tf.expand_dims(input_max, 0), input1, input2])\n",
    "min_intermediate_output = intermediate_layer_model([tf.expand_dims(input_min, 0), input1, input2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output = intermediate_layer_model([tf.expand_dims(input, 0), input1, input2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpis = intermediate_output.numpy()\n",
    "numpis_max = max_intermediate_output.numpy()\n",
    "numpis_min = min_intermediate_output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpis_reshaped = numpis.squeeze()\n",
    "numpis_reshaped_max = numpis_max.squeeze()\n",
    "numpis_reshaped_min = numpis_min.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(numpis_reshaped_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06850497"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(numpis_reshaped_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 110, 12)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpis_reshaped_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpis_reshaped_transposed = np.transpose(numpis_reshaped, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 75, 110)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpis_reshaped_transposed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = some_image / 255.0\n",
    "h, w = image.shape\n",
    "Ix = np.gradient(image, axis=1)\n",
    "Iy = np.gradient(image, axis=0)\n",
    "Ixx = np.gradient(Ix, axis=1)\n",
    "Ixy = np.gradient(Ix, axis=0)\n",
    "Iyy = np.gradient(Iy, axis=0)\n",
    "gradient_magnitude = np.sqrt(Ix**2 + Iy**2)\n",
    "gradient_direction = np.arctan2(Iy, Ix)\n",
    "xn = np.tile(np.arange(w) / w, (h, 1))\n",
    "yn = np.tile(np.arange(h) / h, (w, 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = np.stack([\n",
    "        image, Ix, Iy, Ixx, Ixy, Iyy, gradient_magnitude, gradient_direction, xn, yn\n",
    "    ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 150, 220)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 33000)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map.reshape(10, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_reshaped = np.transpose(feature_map, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 150, 220)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 220, 10)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cedar_gen = 'C:\\\\Users\\\\ester\\\\faculdade\\\\tcc\\\\database_cedar\\\\signatures\\\\full_org'\n",
    "path_cedar_forg = 'C:\\\\Users\\\\ester\\\\faculdade\\\\tcc\\\\database_cedar\\\\signatures\\\\full_forg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = os.listdir(path_cedar_gen)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thumbs.db'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(210, 308, 1))\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(96, (11, 11), activation='relu', strides=4, padding='same')(input_layer)\n",
    "batch1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "\n",
    "pool1 = tf.keras.layers.MaxPooling2D((3, 3), strides=2)(batch1)\n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', strides=1, padding='same')(pool1)\n",
    "batch3 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "\n",
    "pool2 = tf.keras.layers.MaxPooling2D((3, 3), strides=2)(batch3)\n",
    "\n",
    "conv3 = tf.keras.layers.Conv2D(384, (3, 3), activation='relu', strides=1, padding='same')(pool2)\n",
    "batch5 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "\n",
    "conv4 = tf.keras.layers.Conv2D(384, (3, 3), activation='relu', strides=1, padding='same')(batch5)\n",
    "batch6 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "\n",
    "conv5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', strides=1, padding='same')(batch6)\n",
    "#conv5 = tf.keras.layers.Conv2D(300, (3, 3), activation='relu', strides=1, padding='same')(batch6)\n",
    "batch7 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "\n",
    "pool3 = tf.keras.layers.MaxPooling2D((3, 3), strides=2, padding='same')(batch7)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(pool3)\n",
    "#flatten = tf.keras.layers.Flatten()(batch7)\n",
    "\n",
    "l2 = tf.keras.regularizers.L2(l2=1e-4)\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(3234, activation='relu')(flatten)\n",
    "batch9 = tf.keras.layers.BatchNormalization()(dense1)\n",
    "dense2 = tf.keras.layers.Dense(3234, activation='relu')(batch9)\n",
    "batch10 = tf.keras.layers.BatchNormalization()(dense2)\n",
    "\n",
    "output1 = tf.keras.layers.Dense(531, activation='softmax', kernel_regularizer=l2, name='output1')(batch10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[input_layer], outputs=[output1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 12, 18, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries_of_covariance_matrices_path = 'dictionaries-of-covariance-matrices\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_p_values = [(1, 7), (1, 8), (1, 9), (1, 10), (2, 3), (2, 4), (2, 5), (3, 3)]\n",
    "max_iterations = [3000, 5000, 7000, 9000]\n",
    "\n",
    "combinations = list(product(m_p_values, max_iterations))\n",
    "\n",
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "data = []\n",
    "\n",
    "for subdir, _, files in os.walk(dictionaries_of_covariance_matrices_path):\n",
    "\n",
    "    for file in files:\n",
    "        with open(os.path.join(dictionaries_of_covariance_matrices_path, file), 'rb') as pickle_file:\n",
    "            loaded_data = pickle.load(pickle_file)\n",
    "            data.extend(loaded_data)\n",
    "\n",
    "        count += 1\n",
    "        if count == 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dict['forged_scm'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(images):\n",
    "    processed_images = []\n",
    "    for image in images:\n",
    "        height, width = image.shape[:2]\n",
    "        if height > 800 or width > 800:\n",
    "            max_dim = max(height, width)\n",
    "            pad_height = max(0, max_dim - height)\n",
    "            pad_width = max(0, max_dim - width)\n",
    "            padded_image = np.pad(image, ((0, pad_height), (0, pad_width)), mode='constant', constant_values=0)\n",
    "            resized_image = resize(padded_image, (800, 800), anti_aliasing=True)\n",
    "        else:\n",
    "            pad_height = max(0, 800 - height)\n",
    "            pad_width = max(0, 800 - width)\n",
    "            resized_image = np.pad(image, ((0, pad_height), (0, pad_width)), mode='constant', constant_values=0)\n",
    "        processed_images.append(resized_image)\n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 9], [4, 2], [10, 5], [1, 6], [3, 7]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def divide_into_parts(lst, num_parts):\n",
    "    random.shuffle(lst)  # Shuffle the list randomly\n",
    "    part_size = len(lst) // num_parts\n",
    "    remainder = len(lst) % num_parts\n",
    "    parts = [lst[i * part_size + min(i, remainder):(i + 1) * part_size + min(i + 1, remainder)] for i in range(num_parts)]\n",
    "    return parts\n",
    "\n",
    "# Example usage:\n",
    "# lst is your list of integers\n",
    "lst = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "num_parts = 5\n",
    "parts = divide_into_parts(lst, num_parts)\n",
    "print(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('scm_new_features_gpds_prot_2_supernova', 'scm_gpds_protocol_2_new_features_1-400.pkl'), 'rb') as pickle_file:\n",
    "    loaded_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([82, 356, 350, 151, 28, 59, 15, 41, 75, 128, 42, 17, 395, 200, 307, 46, 79, 81, 68, 127, 369, 111, 281, 216, 37, 261, 243, 279, 396, 120, 236, 230, 211, 124, 101, 131, 93, 378, 203, 118, 229, 241, 125, 357, 237, 210, 117, 22, 218, 53, 342, 179, 391, 95, 126, 239, 163, 108, 193, 33, 271, 313, 197, 94, 389, 362, 290, 267, 60, 262, 245, 6, 368, 160, 372, 132, 381, 99, 228, 87, 170, 173, 168, 220, 259, 123, 254, 385, 66, 274, 250, 48, 272, 109, 153, 167, 54, 11, 215, 1, 370, 165, 149, 231, 122, 251, 181, 277, 67, 249, 217, 133, 224, 191, 143, 152, 195, 192, 58, 175, 10, 80, 104, 335, 343, 306, 61, 263, 246, 182, 183, 252, 29, 146, 40, 196, 4, 71, 107, 145, 161, 375, 202, 140, 296, 139, 226, 26, 240, 162, 43, 322, 233, 21, 105, 100, 45, 30, 371, 174, 78, 399, 278, 227, 180, 366, 315, 91, 98, 171, 235, 189, 347, 89, 256, 39, 363, 134, 150, 367, 136, 141, 69, 340, 284, 8, 238, 355, 204, 155, 329, 299, 352, 344, 358, 223, 242, 330, 320, 190, 52, 309, 74, 77, 294, 64, 266, 72, 351, 178, 138, 275, 184, 265, 103, 311, 188, 287, 51, 301, 298, 209, 286, 129, 268, 56, 219, 319, 244, 34, 9, 297, 172, 314, 248, 269, 345, 232, 334, 390, 379, 110, 260, 332, 328, 142, 300, 38, 102, 116, 73, 166, 88, 86, 115, 176, 222, 308, 221, 44, 253, 23, 16, 57, 90, 333, 273, 207, 302, 310, 31, 324, 114, 398, 374, 318, 159, 156, 293, 14, 198, 348, 62, 130, 92, 154, 384, 24, 36, 113, 234, 213, 25, 326, 365, 336, 349, 55, 212, 394, 339, 258, 392, 50, 377, 380, 7, 147, 70, 83, 376, 295, 19, 292, 85, 148, 353, 187, 393, 285, 157, 387, 137, 325, 63, 312, 2, 331, 199, 386, 354, 96, 289, 346, 291, 280, 303, 208, 360, 185, 338, 225, 276, 323, 257, 305, 18, 135, 288, 214, 255, 158, 383, 359, 382, 316, 35, 201, 341, 27, 282, 144, 317, 84, 47, 321, 177, 5, 106, 270, 283, 373, 164, 97, 121, 112, 361, 65, 206, 76, 3, 364, 32, 194, 169, 205, 327, 400, 337, 119, 20, 247, 186, 12, 397, 49, 388, 13, 304, 264])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 48, 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2213.1208"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matrices = [gen for gen in loaded_data[10]['forged_scm']]\n",
    "all_mat_np = np.array(all_matrices)\n",
    "print(all_mat_np.shape)\n",
    "np.max(all_mat_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004908392"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(loaded_data[24]['genuine_scm'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1361,\n",
       " 1138,\n",
       " 2638,\n",
       " 2648,\n",
       " 1432,\n",
       " 1095,\n",
       " 1362,\n",
       " 1447,\n",
       " 1475,\n",
       " 1494,\n",
       " 2457,\n",
       " 1167,\n",
       " 1207,\n",
       " 1480,\n",
       " 1311,\n",
       " 1085,\n",
       " 1398,\n",
       " 2488,\n",
       " 2522,\n",
       " 1457,\n",
       " 1173,\n",
       " 1276,\n",
       " 1081,\n",
       " 1287,\n",
       " 1477,\n",
       " 1451,\n",
       " 1415]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['fold_results'][2]['test_users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['individual', 'genuine_signatures', 'forged_signatures', 'genuine_scm', 'forged_scm'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39 % 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5436375, 0.57975, 0.568325, 0.5372750000000001, 0.5497749999999999]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['fold_results'][2]['aucs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 101, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 102, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 103, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 104, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 105, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 106, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 107, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 108, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 109, 1090, "
     ]
    }
   ],
   "source": [
    "for data in loaded_data:\n",
    "    print(data['individual'], end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {'oi': 'hi'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listo = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seto = {'oi', 'ola'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "def calculate_center_of_mass(image):\n",
    "    # Calculate center of mass\n",
    "    center_of_mass = ndimage.measurements.center_of_mass(image)\n",
    "    return center_of_mass\n",
    "\n",
    "def shift_image(image, shift):\n",
    "    # Shift the image\n",
    "    shifted_image = ndimage.shift(image, shift)\n",
    "    return shifted_image\n",
    "\n",
    "def centerize_image(image_path, output_size):\n",
    "    # Read the image\n",
    "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Calculate center of mass\n",
    "    center_of_mass = calculate_center_of_mass(img_array)\n",
    "\n",
    "    # Calculate shift needed\n",
    "    shift = np.array(output_size) / 2 - np.array(center_of_mass)\n",
    "\n",
    "    # Shift the image\n",
    "    shifted_image = shift_image(img_array, shift)\n",
    "\n",
    "    # Create a larger canvas\n",
    "    larger_canvas = np.zeros(output_size, dtype=np.uint8)\n",
    "\n",
    "    # Calculate position to paste the shifted image onto the larger canvas\n",
    "    paste_position = tuple((np.array(output_size) - np.array(img_array.shape)) // 2)\n",
    "\n",
    "    # Paste the shifted image onto the larger canvas\n",
    "    larger_canvas[paste_position[0]:paste_position[0]+img_array.shape[0], \n",
    "                  paste_position[1]:paste_position[1]+img_array.shape[1]] = shifted_image\n",
    "\n",
    "    # Convert back to image\n",
    "    centered_image = Image.fromarray(larger_canvas)\n",
    "\n",
    "    return centered_image\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'your_image.jpg'  # Path to your input image\n",
    "output_size = (800, 600)  # Desired output size of the canvas\n",
    "centered_image = centerize_image(image_path, output_size)\n",
    "centered_image.show()  # Display the resulting image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
